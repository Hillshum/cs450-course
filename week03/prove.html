<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>CS 450 - Prove</title>
    <link rel="stylesheet" type="text/css" href="../course/style2018.css" />
</head>

<body>
    <div id="courseTitle">
        <span class="icon-byui-logo"></span>
        <h1>Machine Learning &amp; Data Mining | CS 450</h1>
    </div>
    <article>

            <h2>03 Prove : Assignment</h2>
            <p class="subtitle">kNN with More Interesting Data</p>

            <h3>Objective</h3>
            <p>Be able to use datasets with more interesting data than just the built-in, all numeric datasets.</p>

            <h3>Instructions</h3>
            <p>Add to your kNN classifier code from last week. This week, you need to add the ability to work with non-trivial data. In particular you need to add the following functionality:</p>

            <ol>
                <li><p>Read data from CSV files</p></li>
                <li><p>Handle non-numeric data</p></li>
                <li><p>Handle missing data</p></li>
            </ol>

            <p>To help do the following, you should use the library <code>pandas</code> which is a nice data science library that helps with pre-processing. Then, when the dataset is prepared, you'll need to convert it to a plain numpy array (rather than a Pandas DataFrame) to use with your existing code.</p>

            <h4>Hard-coded or General-purpose?</h4>
            <p>One question that always comes up when doing this kind of work is how much should your code be general-purpose versus tailed specifically to a particular data. This is a difficult question to answer, and there should be a balance of somewhere in between.</p>

            <p>Two principles will likely apply:</p>
            <ol>
                <li><p>We should make it as general-purpose as we can, but</p></li>
                <li><p>Almost all pre-processing code I have seen is messy and feels hardcoded to that dataset</p></li>
            </ol>
            <p>In the real-world, most companies have very specific datasets that they care about, and they aren't interested in trying to make code work on hundreds of others, they just want to get their data in place. With that in mind, our goal should be to decouple the pre-processing logic from our algorithms as much as possible.</p>

            <p>To this end, you should create a separate function to load each dataset. It can (and will) do as many messy things as you'd like, but when it is done, it should return two <code>NumPy</code> arrays, one for the data, and one for the targets.</p>

<!--             <h4>Suggestions</h4>

            <ul>
                <li><p>Reading data from .csv files - This is SUPER easy with Pandas. If you are writing lots of code to do this, you are probably over-thinking things.</p></li>
                <li><p>Categorical Data - Check out: for some great tips.</p></li>
                <li><p>Missing Data - There is not a universal answer here. How should this be treated? Should you ignore these rows? Should you come up with values to fill in? If so, how?</p></li>
            </ul>
 -->
            <h3>Experiment Guidelines</h3>
            <p>Please use the following datasets:</p>

            <ul>
                <li><p></p></li>
                <li><p></p></li>
                <li><p></p></li>
                <li><p></p></li>
            </ul>

            <p>For each dataset, use your kNN classifier from last week with varying values for <em>k</em>. Also, if possible, see how your results compare against an off-the-shelf implementation of kNN.</p>


            <h3>Requirements</h3>
            <p>As always, you are encouraged to go above and beyond and take initiative in your learning. As described in the syllabus, meeting the minimum standard requirements can qualify you for 93%, but going above and beyond is necessary to get 100%. The following are the expectations for a minimum standard, with a few suggestions for going above and beyond.</p>
            <h4>Minimum Standard Requirements</h4>
            <ol>
                <li><p>Read data from .csv files</p></li>
                <li><p>Appropriately handle non-numeric data.</p></li>
                <li><p>Appropriately handle missing data.</p></li>
                <li><p>Basic experimentation on the provided datasets.</p></li>
            </ol>

            <h4>Some opportunities to go above and beyond:</h4>
            <ul>
                <li><p>Explore multiple options for handling non-numeric data, comparing the results of each approach.</p></li>
                <li><p>Explore multiple options for handling missing data, comparing the results of each approach.</p></li>
                <li><p>Experimentation with several additional data sets.</p></li>
                <li><p>Using data that comes in a more complex manner than a simple downloadable .csv file.</p></li>
                 <li><p>Any other ideas you have.</p></li>
            </ul>


            <h3>Submission</h3>
            <p>When complete, push your code to a public GitHub repository and answer the questions in the <a href="./prove03.txt">submission txt file</a>. There were some issues with the PDF process from last week, so we are going to use a .txt file this week to see if it is easier. Please fill it out and upload it to I-Learn.</p>

        </article>

   <script src="../course/js/highlight/highlight.pack.js"></script>
   <script>hljs.initHighlightingOnLoad();</script>


</body>

</html>